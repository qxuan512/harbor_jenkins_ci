pipeline {
    agent {
        kubernetes {
            yaml '''
kind: Pod
spec:
  containers:
  - name: python
    image: python:3.9-slim
    imagePullPolicy: Always
    command:
    - sleep
    args:
    - 9999999
  - name: kaniko
    image: gcr.io/kaniko-project/executor:debug
    imagePullPolicy: Always
    command:
    - sleep
    args:
    - 9999999
    volumeMounts:
      - name: jenkins-docker-cfg
        mountPath: /kaniko/.docker
    env:
    - name: DOCKER_CONFIG
      value: /kaniko/.docker
  volumes:
  - name: jenkins-docker-cfg
    projected:
      sources:
      - secret:
          name: harbor-credentials
          items:
            - key: .dockerconfigjson
              path: config.json
            '''
        }
    }

    parameters {
        // Allow external programs to trigger builds via parameters
        string(name: 'APP_NAME', defaultValue: 'iot-driver', description: 'Application name')
        string(name: 'APP_VERSION', defaultValue: '1.0.0', description: 'Application version')
        string(name: 'BUILD_CONTEXT', defaultValue: 'example_direct_upload', description: 'Build context directory')
        choice(name: 'IMAGE_TAG_STRATEGY', choices: ['version-build', 'timestamp', 'latest'], description: 'Image tag strategy')
        // Build platform parameters - support multi-platform builds
        choice(name: 'BUILD_PLATFORMS', 
               choices: ['linux/amd64', 'linux/arm64', 'linux/amd64,linux/arm64'], 
               description: 'Build platform selection (supports multi-platform parallel builds)')
        // Unique ID parameter to ensure uniqueness of each build job
        string(name: 'BUILD_UNIQUE_ID', defaultValue: '', description: 'Build unique identifier (optional, used to ensure build uniqueness, auto-generated if left empty)')
        // Add file upload parameter
        stashedFile(name: 'BUILD_ARCHIVE', description: 'Upload compressed file containing build context (supports .zip, .tar, .tar.gz)')
    }

    environment {
        // Harbor repository configuration
        HARBOR_REGISTRY = "registry.test.shifu.dev"
        HARBOR_PROJECT = "test-project"
        DOCKER_USER = "admin"
        DOCKER_PASS = 'harbor-credentials'  // Jenkins credentials ID
        
        // Image configuration
        IMAGE_NAME = "${HARBOR_REGISTRY}/${HARBOR_PROJECT}/${params.APP_NAME}"
        IMAGE_TAG = generateImageTag()
        
        // Build configuration
        DOCKERFILE_PATH = "${params.BUILD_CONTEXT}/Dockerfile"
        BUILD_CONTEXT_PATH = "${params.BUILD_CONTEXT}"
        
        // Platform configuration
        BUILD_PLATFORMS = "${params.BUILD_PLATFORMS}"
    }

    stages {
        stage("Clean Workspace") {
            steps {
                container('python') {
                    cleanWs()
                }
            }
        }

        stage("Build Preparation") {
            steps {
                container('python') {
                    script {
                        echo "üì¶ Starting to process uploaded build files"
                        
                        // Get the original filename of uploaded file
                        def originalFilename = env.BUILD_ARCHIVE_FILENAME
                        echo "Uploaded filename: ${originalFilename}"
                        
                        // Restore uploaded file from stash
                        unstash 'BUILD_ARCHIVE'
                        
                        // Check file and determine actual filename
                        sh """
                            echo "üìã Checking uploaded file information..."
                            ls -la BUILD_ARCHIVE* || true
                            
                            # Check if original filename exists
                            if [ -n "\${BUILD_ARCHIVE_FILENAME}" ] && [ "\${BUILD_ARCHIVE_FILENAME}" != "null" ]; then
                                echo "‚úÖ Using original filename: \${BUILD_ARCHIVE_FILENAME}"
                                if [ -f "BUILD_ARCHIVE" ]; then
                                    mv BUILD_ARCHIVE "\${BUILD_ARCHIVE_FILENAME}"
                                fi
                                ARCHIVE_FILE="\${BUILD_ARCHIVE_FILENAME}"
                            else
                                echo "‚ö†Ô∏è  Filename is empty or null, trying to detect file type"
                                # Use file command to detect file type
                                FILE_TYPE=\$(file BUILD_ARCHIVE 2>/dev/null || echo "unknown")
                                echo "File type detection: \$FILE_TYPE"
                                
                                if echo "\$FILE_TYPE" | grep -q "Zip archive"; then
                                    ARCHIVE_FILE="BUILD_ARCHIVE.zip"
                                    mv BUILD_ARCHIVE "\$ARCHIVE_FILE"
                                    echo "‚úÖ Detected as ZIP file, renamed to: \$ARCHIVE_FILE"
                                elif echo "\$FILE_TYPE" | grep -q "gzip compressed"; then
                                    ARCHIVE_FILE="BUILD_ARCHIVE.tar.gz"
                                    mv BUILD_ARCHIVE "\$ARCHIVE_FILE"
                                    echo "‚úÖ Detected as TAR.GZ file, renamed to: \$ARCHIVE_FILE"
                                elif echo "\$FILE_TYPE" | grep -q "POSIX tar archive"; then
                                    ARCHIVE_FILE="BUILD_ARCHIVE.tar"
                                    mv BUILD_ARCHIVE "\$ARCHIVE_FILE"
                                    echo "‚úÖ Detected as TAR file, renamed to: \$ARCHIVE_FILE"
                                else
                                    ARCHIVE_FILE="BUILD_ARCHIVE"
                                    echo "‚ö†Ô∏è  Unable to recognize file type, using default name: \$ARCHIVE_FILE"
                                fi
                            fi
                            
                            echo "Final filename used: \$ARCHIVE_FILE"
                            echo "ARCHIVE_FILE=\$ARCHIVE_FILE" > archive_info.env
                        """
                        
                        // Read filename information
                        def archiveInfo = readFile('archive_info.env').trim()
                        def archiveFile = archiveInfo.split('=')[1]
                        env.ACTUAL_ARCHIVE_FILE = archiveFile
                        
                        echo "Determined archive file: ${env.ACTUAL_ARCHIVE_FILE}"
                        
                        // Detect file type and extract - using Pipeline Utility Steps
                        script {
                            def uploadedArchive = env.ACTUAL_ARCHIVE_FILE
                            
                            echo "üìã File information:"
                            sh "ls -lh '${uploadedArchive}'"
                            
                            echo "üìÇ Starting to extract file: ${uploadedArchive}"
                            
                            // Use appropriate Pipeline Utility Steps based on file extension
                            try {
                                if (uploadedArchive.endsWith('.zip')) {
                                    echo "Using Pipeline Utility Steps unzip to extract ZIP file"
                                    unzip zipFile: uploadedArchive, quiet: false
                                    echo "‚úÖ ZIP file extraction completed"
                                } else if (uploadedArchive.endsWith('.tar.gz') || uploadedArchive.endsWith('.tgz')) {
                                    echo "Using Pipeline Utility Steps untar to extract TAR.GZ file"
                                    untar file: uploadedArchive, compression: 'gzip', quiet: false
                                    echo "‚úÖ TAR.GZ file extraction completed"
                                } else if (uploadedArchive.endsWith('.tar')) {
                                    echo "Using Pipeline Utility Steps untar to extract TAR file"
                                    untar file: uploadedArchive, quiet: false
                                    echo "‚úÖ TAR file extraction completed"
                                } else {
                                    echo "‚ö†Ô∏è  Unknown file format, trying generic extraction methods"
                                    // Try as ZIP file first
                                    try {
                                        echo "Trying to extract as ZIP format"
                                        unzip zipFile: uploadedArchive, quiet: false
                                        echo "‚úÖ Successfully extracted as ZIP format"
                                    } catch (Exception zipEx) {
                                        echo "ZIP extraction failed, trying TAR format"
                                        try {
                                            untar file: uploadedArchive, quiet: false
                                            echo "‚úÖ Successfully extracted as TAR format"
                                        } catch (Exception tarEx) {
                                            echo "TAR extraction failed, trying TAR.GZ format"
                                            untar file: uploadedArchive, compression: 'gzip', quiet: false
                                            echo "‚úÖ Successfully extracted as TAR.GZ format"
                                        }
                                    }
                                }
                            } catch (Exception e) {
                                echo "‚ùå Pipeline Utility Steps extraction failed: ${e.getMessage()}"
                                echo "Falling back to traditional extraction methods..."
                                
                                // Fallback to traditional command line extraction
                                if (uploadedArchive.endsWith('.zip')) {
                                    echo "Using Python to extract ZIP file"
                                    sh '''
                                        python3 -c "
import zipfile
import sys
try:
    with zipfile.ZipFile('${uploadedArchive}', 'r') as zip_ref:
        zip_ref.extractall('.')
    print('‚úÖ Python ZIP extraction successful')
except Exception as e:
    print(f'‚ùå Python ZIP extraction failed: {e}')
    sys.exit(1)
                                    "
                                '''
                                } else if (uploadedArchive.endsWith('.tar.gz') || uploadedArchive.endsWith('.tgz')) {
                                    echo "Using tar to extract TAR.GZ file"
                                    sh "tar -xzf '${uploadedArchive}'"
                                } else if (uploadedArchive.endsWith('.tar')) {
                                    echo "Using tar to extract TAR file"
                                    sh "tar -xf '${uploadedArchive}'"
                                }
                            }
                            
                            echo "üìÅ Workspace contents after extraction:"
                            sh "ls -la"
                        }
                        
                        // Verify build directory and files exist
                        sh """
                            if [ ! -d "${BUILD_CONTEXT_PATH}" ]; then
                                echo "‚ùå Error: Build directory ${BUILD_CONTEXT_PATH} does not exist"
                                echo "üìÅ Current directory contents:"
                                find . -type d -maxdepth 2
                                exit 1
                            fi
                            
                            if [ ! -f "${DOCKERFILE_PATH}" ]; then
                                echo "‚ùå Error: Dockerfile ${DOCKERFILE_PATH} does not exist"
                                echo "üìÅ Build directory contents:"
                                ls -la ${BUILD_CONTEXT_PATH}/
                                exit 1
                            fi
                            
                            echo "‚úÖ Build file verification passed"
                            echo "üìÅ Build directory contents:"
                            ls -la ${BUILD_CONTEXT_PATH}/
                        """

                        echo "üîß Build preparation stage"
                        
                        // Handle unique ID - usually generated and passed by Python script
                        def uniqueId = params.BUILD_UNIQUE_ID
                        if (!uniqueId || uniqueId.trim().isEmpty()) {
                            uniqueId = "${new Date().format('yyyyMMddHHmmss')}-${BUILD_NUMBER}-${UUID.randomUUID().toString().substring(0, 8)}"
                            echo "üìã Jenkins generated unique ID: ${uniqueId}"
                        } else {
                            echo "üìã Using passed unique ID: ${uniqueId}"
                        }
                        env.ACTUAL_UNIQUE_ID = uniqueId
                        
                        // Handle platform configuration
                        def platformsStr = params.BUILD_PLATFORMS
                        echo "üîç Original platform parameter: '${platformsStr}'"
                        
                        def platforms = platformsStr.split(',')
                        def platformsInfo = []
                        
                        echo "üèóÔ∏è  Multi-platform build configuration:"
                        echo "   Selected platforms: ${platformsStr}"
                        echo "   Number of platforms after split: ${platforms.length}"
                        
                        for (platform in platforms) {
                            def cleanPlatform = platform.trim()
                            platformsInfo.add(cleanPlatform)
                            echo "   - Platform: '${cleanPlatform}'"
                        }
                        
                        env.PLATFORM_LIST = platformsInfo.join(',')
                        env.IS_MULTI_PLATFORM = (platforms.length > 1).toString()
                        
                        echo "üîç Environment variable settings:"
                        echo "   PLATFORM_LIST: '${env.PLATFORM_LIST}'"
                        echo "   IS_MULTI_PLATFORM: '${env.IS_MULTI_PLATFORM}'"
                        
                        echo "üìã Build configuration information:"
                        echo "   Application name: ${params.APP_NAME}"
                        echo "   Application version: ${params.APP_VERSION}" 
                        echo "   Build unique ID: ${uniqueId}"
                        echo "   Image name: ${IMAGE_NAME}"
                        echo "   Image tag: ${IMAGE_TAG}"
                        echo "   Harbor registry: ${HARBOR_REGISTRY}"
                        echo "   Project: ${HARBOR_PROJECT}"
                        echo "   Build platforms: ${env.PLATFORM_LIST}"
                        echo "   Multi-platform build: ${env.IS_MULTI_PLATFORM}"
                        
                        // Display build information
                        sh """
                            echo "=== Build Information ==="
                            echo "Build number: ${BUILD_NUMBER}"
                            echo "Build unique ID: ${uniqueId}"
                            echo "Build time: \$(date)"
                            echo "Build node: \$(hostname)"
                            echo "Jenkins URL: ${JENKINS_URL}"
                            echo "Original filename: \${BUILD_ARCHIVE_FILENAME:-'Not set'}"
                            echo "Actually used file: ${env.ACTUAL_ARCHIVE_FILE}"
                            echo "Build platforms: ${env.PLATFORM_LIST}"
                            echo "Multi-platform mode: ${env.IS_MULTI_PLATFORM}"
                        """

                        echo "üì¶ Stashing build context for parallel stages..."
                        echo "üìÅ Verifying directory contents to stash:"
                        sh "ls -la ${params.BUILD_CONTEXT}/"
                        stash includes: "${params.BUILD_CONTEXT}/**", name: "build-context-${env.ACTUAL_UNIQUE_ID}"
                    }
                }
            }
        }

        stage("Multi-platform Image Build") {
            steps {
                script {
                    def platforms = env.PLATFORM_LIST.split(',')
                    echo "üöÄ Starting to build ${platforms.length} platforms: ${env.PLATFORM_LIST}"
                }
            }
        }
        
        stage("Parallel Build Execution") {
            failFast true
            parallel {
                stage('Build AMD64') {
                    when {
                        expression { 
                            return env.PLATFORM_LIST.contains('linux/amd64')
                        }
                    }
                    agent {
                        kubernetes {
                            yaml '''
kind: Pod
spec:
  containers:
  - name: kaniko
    image: gcr.io/kaniko-project/executor:debug
    imagePullPolicy: Always
    command:
    - sleep
    args:
    - 9999999
    volumeMounts:
      - name: jenkins-docker-cfg
        mountPath: /kaniko/.docker
    env:
    - name: DOCKER_CONFIG
      value: /kaniko/.docker
  volumes:
  - name: jenkins-docker-cfg
    projected:
      sources:
      - secret:
          name: harbor-credentials
          items:
            - key: .dockerconfigjson
              path: config.json
            '''
                        }
                    }
                    steps {
                        script {
                            echo "üñ•Ô∏è  Building AMD64 image"
                            echo "üì¶ Unstashing build context..."
                            unstash name: "build-context-${env.ACTUAL_UNIQUE_ID}"
                            container('kaniko') {
                                buildPlatformImage('linux/amd64', 'amd64')
                            }
                        }
                    }
                    post {
                        failure {
                            echo "‚ùå AMD64 failed"
                        }
                    }
                }
                
                stage('Build ARM64') {
                    when {
                        expression { 
                            return env.PLATFORM_LIST.contains('linux/arm64')
                        }
                    }
                    agent {
                        kubernetes {
                            yaml '''
kind: Pod
spec:
  containers:
  - name: kaniko
    image: gcr.io/kaniko-project/executor:debug
    imagePullPolicy: Always
    command:
    - sleep
    args:
    - 9999999
    volumeMounts:
      - name: jenkins-docker-cfg
        mountPath: /kaniko/.docker
    env:
    - name: DOCKER_CONFIG
      value: /kaniko/.docker
  volumes:
  - name: jenkins-docker-cfg
    projected:
      sources:
      - secret:
          name: harbor-credentials
          items:
            - key: .dockerconfigjson
              path: config.json
            '''
                        }
                    }
                    steps {
                        script {
                            echo "üí™ Building ARM64 image"
                            echo "üì¶ Unstashing build context..."
                            unstash name: "build-context-${env.ACTUAL_UNIQUE_ID}"
                            container('kaniko') {
                                buildPlatformImage('linux/arm64', 'arm64')
                            }
                        }
                    }
                    post {
                        failure {
                            echo "‚ùå ARM64 failed"
                        }
                    }
                }
            }
        }

        stage("Build Results Summary") {
            steps {
                script {
                    def platforms = env.PLATFORM_LIST.split(',')
                    def builtPlatforms = []
                    
                    for (platform in platforms) {
                        def cleanPlatform = platform.trim()
                        if (cleanPlatform == 'linux/amd64' || cleanPlatform == 'linux/arm64') {
                            builtPlatforms.add(cleanPlatform)
                        }
                    }
                    
                    echo "üìä Build completed: ${params.APP_NAME}:${IMAGE_TAG} (${builtPlatforms.size()} platforms)"
                    echo ""
                    echo "üéØ Built images:"
                    
                    for (platform in builtPlatforms) {
                        def platformArch = platform.replace('linux/', '')
                        echo "   ${IMAGE_NAME}:${IMAGE_TAG}-${platformArch}"
                        echo "   ${IMAGE_NAME}:latest-${platformArch}"
                    }
                    
                    echo ""
                    echo "üåê Harbor: ${HARBOR_REGISTRY}/harbor/projects/${HARBOR_PROJECT}/repositories/${params.APP_NAME}"
                }
            }
        }
    }

    post {
        always {
            script {
                echo "üßπ Build completed - Number: ${BUILD_NUMBER}"
            }
        }
        success {
            script {
                def platforms = env.PLATFORM_LIST?.split(',') ?: []
                def builtPlatforms = []
                
                for (platform in platforms) {
                    def cleanPlatform = platform.trim()
                    if (cleanPlatform == 'linux/amd64' || cleanPlatform == 'linux/arm64') {
                        builtPlatforms.add(cleanPlatform.replace('linux/', ''))
                    }
                }
                
                echo "üéâ Build successful - ${params.APP_NAME}:${IMAGE_TAG}"
                echo "‚úÖ Platforms: ${builtPlatforms.join(', ')}"
            }
        }
        failure {
            script {
                echo "‚ùå Build failed - ${params.APP_NAME}:${IMAGE_TAG}"
            }
        }
    }
}

// Function to generate image tag
def generateImageTag() {
    def strategy = params.IMAGE_TAG_STRATEGY ?: 'version-build'
    
    switch(strategy) {
        case 'version-build':
            return "${params.APP_VERSION}"
        case 'timestamp':
            return "${params.APP_VERSION}-${new Date().format('yyyyMMdd-HHmmss')}"
        case 'latest':
            return 'latest'
        default:
            return "${params.APP_VERSION}"
    }
}

// Function to parse platform list
def parsePlatforms(platformsStr) {
    return platformsStr.split(',').collect { it.trim() }.join(',')
}

// Function to build image for specified platform
def buildPlatformImage(String platform, String platformArch) {
    sh """#!/busybox/sh
        # Verify files
        if [ ! -f "${DOCKERFILE_PATH}" ]; then
            echo "‚ùå Dockerfile does not exist: ${DOCKERFILE_PATH}"
            exit 1
        fi
        
        # Execute build
        /kaniko/executor \\
            --dockerfile=${DOCKERFILE_PATH} \\
            --context=${BUILD_CONTEXT_PATH} \\
            --destination=${IMAGE_NAME}:${IMAGE_TAG}-${platformArch} \\
            --destination=${IMAGE_NAME}:latest-${platformArch} \\
            --custom-platform=${platform} \\
            --build-arg=TARGETARCH=${platformArch} \\
            --build-arg=BUILDPLATFORM=${platform} \\
            --cache=true \\
            --cache-ttl=24h \\
            --cleanup
    """
}