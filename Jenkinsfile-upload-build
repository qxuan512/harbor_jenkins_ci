pipeline {
    agent none

    parameters {
        // å…è®¸å¤–éƒ¨ç¨‹åºé€šè¿‡å‚æ•°è§¦å‘æ„å»º
        string(name: 'APP_NAME', defaultValue: 'iot-driver', description: 'åº”ç”¨åç§°')
        string(name: 'APP_VERSION', defaultValue: '1.0.0', description: 'åº”ç”¨ç‰ˆæœ¬')
        string(name: 'BUILD_CONTEXT', defaultValue: 'example_direct_upload', description: 'æ„å»ºä¸Šä¸‹æ–‡ç›®å½•')
        choice(name: 'IMAGE_TAG_STRATEGY', choices: ['version-build', 'timestamp', 'latest'], description: 'é•œåƒæ ‡ç­¾ç­–ç•¥')
        // æ„å»ºå¹³å°å‚æ•° - æ”¯æŒå¤šå¹³å°æ„å»º
        choice(name: 'BUILD_PLATFORMS', 
               choices: ['linux/amd64', 'linux/arm64', 'linux/amd64,linux/arm64'], 
               description: 'æ„å»ºå¹³å°é€‰æ‹© (æ”¯æŒå¤šå¹³å°å¹¶è¡Œæ„å»º)')
        // å”¯ä¸€IDå‚æ•°ï¼Œç¡®ä¿æ¯ä¸ªæ„å»ºjobçš„å”¯ä¸€æ€§
        string(name: 'BUILD_UNIQUE_ID', defaultValue: '', description: 'æ„å»ºå”¯ä¸€æ ‡è¯†ç¬¦ (å¯é€‰ï¼Œç”¨äºç¡®ä¿æ„å»ºçš„å”¯ä¸€æ€§ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆ)')
        // æ·»åŠ æ–‡ä»¶ä¸Šä¼ å‚æ•°
        stashedFile(name: 'BUILD_ARCHIVE', description: 'ä¸Šä¼ åŒ…å«æ„å»ºä¸Šä¸‹æ–‡çš„å‹ç¼©æ–‡ä»¶ (æ”¯æŒ .zip, .tar, .tar.gz)')
    }

    environment {
        // Harbor ä»“åº“é…ç½®
        HARBOR_REGISTRY = "registry.test.shifu.dev"
        HARBOR_PROJECT = "test-project"
        DOCKER_USER = "admin"
        DOCKER_PASS = 'harbor-credentials'  // Jenkins å‡­æ® ID
        
        // é•œåƒé…ç½®
        IMAGE_NAME = "${HARBOR_REGISTRY}/${HARBOR_PROJECT}/${params.APP_NAME}"
        IMAGE_TAG = generateImageTag()
        
        // æ„å»ºé…ç½®
        DOCKERFILE_PATH = "${params.BUILD_CONTEXT}/Dockerfile"
        BUILD_CONTEXT_PATH = "${params.BUILD_CONTEXT}"
        
        // å¹³å°é…ç½®
        BUILD_PLATFORMS = "${params.BUILD_PLATFORMS}"

        // å®šä¹‰ Kaniko Pod YAML æ¨¡æ¿
        KANIKO_POD_YAML = """
kind: Pod
spec:
  containers:
  - name: kaniko
    image: gcr.io/kaniko-project/executor:debug
    imagePullPolicy: Always
    command:
    - sleep
    args:
    - 9999999
    volumeMounts:
      - name: jenkins-docker-cfg
        mountPath: /kaniko/.docker
    env:
    - name: DOCKER_CONFIG
      value: /kaniko/.docker
  volumes:
  - name: jenkins-docker-cfg
    projected:
      sources:
      - secret:
          name: harbor-credentials
          items:
            - key: .dockerconfigjson
              path: config.json
"""
        // å®šä¹‰ å‡†å¤‡é˜¶æ®µ Pod YAML æ¨¡æ¿
        PREP_POD_YAML = """
kind: Pod
spec:
  containers:
  - name: python
    image: python:3.9-slim
    imagePullPolicy: Always
    command:
    - sleep
    args:
    - 9999999
"""
    }

    stages {
        stage("æ¸…ç†å·¥ä½œç©ºé—´") {
            agent {
                kubernetes {
                    yaml PREP_POD_YAML
                    defaultContainer 'python'
                }
            }
            steps {
                cleanWs()
            }
        }

        stage("å¤„ç†ä¸Šä¼ æ–‡ä»¶") {
            agent {
                kubernetes {
                    yaml PREP_POD_YAML
                    defaultContainer 'python'
                }
            }
            steps {
                script {
                    echo "ğŸ“¦ å¼€å§‹å¤„ç†ä¸Šä¼ çš„æ„å»ºæ–‡ä»¶"
                    
                    // è·å–ä¸Šä¼ æ–‡ä»¶çš„åŸå§‹æ–‡ä»¶å
                    def originalFilename = env.BUILD_ARCHIVE_FILENAME
                    echo "ä¸Šä¼ æ–‡ä»¶å: ${originalFilename}"
                    
                    // ä» stash ä¸­æ¢å¤ä¸Šä¼ çš„æ–‡ä»¶
                    unstash 'BUILD_ARCHIVE'
                    
                    // æ£€æŸ¥æ–‡ä»¶å¹¶ç¡®å®šå®é™…æ–‡ä»¶å
                    sh """
                        echo "ğŸ“‹ æ£€æŸ¥ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯..."
                        ls -la BUILD_ARCHIVE* || true
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹æ–‡ä»¶å
                        if [ -n "\${BUILD_ARCHIVE_FILENAME}" ] && [ "\${BUILD_ARCHIVE_FILENAME}" != "null" ]; then
                            echo "âœ… ä½¿ç”¨åŸå§‹æ–‡ä»¶å: \${BUILD_ARCHIVE_FILENAME}"
                            if [ -f "BUILD_ARCHIVE" ]; then
                                mv BUILD_ARCHIVE "\${BUILD_ARCHIVE_FILENAME}"
                            fi
                            ARCHIVE_FILE="\${BUILD_ARCHIVE_FILENAME}"
                        else
                            echo "âš ï¸  æ–‡ä»¶åä¸ºç©ºæˆ–nullï¼Œå°è¯•æ£€æµ‹æ–‡ä»¶ç±»å‹"
                            # ä½¿ç”¨ file å‘½ä»¤æ£€æµ‹æ–‡ä»¶ç±»å‹
                            FILE_TYPE=\$(file BUILD_ARCHIVE 2>/dev/null || echo "unknown")
                            echo "æ–‡ä»¶ç±»å‹æ£€æµ‹: \$FILE_TYPE"
                            
                            if echo "\$FILE_TYPE" | grep -q "Zip archive"; then
                                ARCHIVE_FILE="BUILD_ARCHIVE.zip"
                                mv BUILD_ARCHIVE "\$ARCHIVE_FILE"
                                echo "âœ… æ£€æµ‹ä¸ºZIPæ–‡ä»¶ï¼Œé‡å‘½åä¸º: \$ARCHIVE_FILE"
                            elif echo "\$FILE_TYPE" | grep -q "gzip compressed"; then
                                ARCHIVE_FILE="BUILD_ARCHIVE.tar.gz"
                                mv BUILD_ARCHIVE "\$ARCHIVE_FILE"
                                echo "âœ… æ£€æµ‹ä¸ºTAR.GZæ–‡ä»¶ï¼Œé‡å‘½åä¸º: \$ARCHIVE_FILE"
                            elif echo "\$FILE_TYPE" | grep -q "POSIX tar archive"; then
                                ARCHIVE_FILE="BUILD_ARCHIVE.tar"
                                mv BUILD_ARCHIVE "\$ARCHIVE_FILE"
                                echo "âœ… æ£€æµ‹ä¸ºTARæ–‡ä»¶ï¼Œé‡å‘½åä¸º: \$ARCHIVE_FILE"
                            else
                                ARCHIVE_FILE="BUILD_ARCHIVE"
                                echo "âš ï¸  æ— æ³•è¯†åˆ«æ–‡ä»¶ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤åç§°: \$ARCHIVE_FILE"
                            fi
                        fi
                        
                        echo "æœ€ç»ˆä½¿ç”¨çš„æ–‡ä»¶å: \$ARCHIVE_FILE"
                        echo "ARCHIVE_FILE=\$ARCHIVE_FILE" > archive_info.env
                    """
                    
                    // è¯»å–æ–‡ä»¶åä¿¡æ¯
                    def archiveInfo = readFile('archive_info.env').trim()
                    def archiveFile = archiveInfo.split('=')[1]
                    env.ACTUAL_ARCHIVE_FILE = archiveFile
                    
                    echo "ç¡®å®šçš„å½’æ¡£æ–‡ä»¶: ${env.ACTUAL_ARCHIVE_FILE}"
                    
                    // æ£€æµ‹æ–‡ä»¶ç±»å‹å¹¶è§£å‹ - ä½¿ç”¨ Pipeline Utility Steps
                    script {
                        def uploadedArchive = env.ACTUAL_ARCHIVE_FILE
                        
                        echo "ğŸ“‹ æ–‡ä»¶ä¿¡æ¯:"
                        sh "ls -lh '${uploadedArchive}'"
                        
                        echo "ğŸ“‚ å¼€å§‹è§£å‹æ–‡ä»¶: ${uploadedArchive}"
                        
                        // æ ¹æ®æ–‡ä»¶æ‰©å±•åä½¿ç”¨é€‚å½“çš„ Pipeline Utility Steps
                        try {
                            if (uploadedArchive.endsWith('.zip')) {
                                echo "ä½¿ç”¨ Pipeline Utility Steps unzip è§£å‹ ZIP æ–‡ä»¶"
                                unzip zipFile: uploadedArchive, quiet: false
                                echo "âœ… ZIP æ–‡ä»¶è§£å‹å®Œæˆ"
                            } else if (uploadedArchive.endsWith('.tar.gz') || uploadedArchive.endsWith('.tgz')) {
                                echo "ä½¿ç”¨ Pipeline Utility Steps untar è§£å‹ TAR.GZ æ–‡ä»¶"
                                untar file: uploadedArchive, compression: 'gzip', quiet: false
                                echo "âœ… TAR.GZ æ–‡ä»¶è§£å‹å®Œæˆ"
                            } else if (uploadedArchive.endsWith('.tar')) {
                                echo "ä½¿ç”¨ Pipeline Utility Steps untar è§£å‹ TAR æ–‡ä»¶"
                                untar file: uploadedArchive, quiet: false
                                echo "âœ… TAR æ–‡ä»¶è§£å‹å®Œæˆ"
                            } else {
                                echo "âš ï¸  æœªçŸ¥æ–‡ä»¶æ ¼å¼ï¼Œå°è¯•é€šç”¨è§£å‹æ–¹æ³•"
                                // å…ˆå°è¯•ä½œä¸º ZIP æ–‡ä»¶
                                try {
                                    echo "å°è¯•æŒ‰ ZIP æ ¼å¼è§£å‹"
                                    unzip zipFile: uploadedArchive, quiet: false
                                    echo "âœ… æŒ‰ ZIP æ ¼å¼è§£å‹æˆåŠŸ"
                                } catch (Exception zipEx) {
                                    echo "ZIP è§£å‹å¤±è´¥ï¼Œå°è¯•æŒ‰ TAR æ ¼å¼è§£å‹"
                                    try {
                                        untar file: uploadedArchive, quiet: false
                                        echo "âœ… æŒ‰ TAR æ ¼å¼è§£å‹æˆåŠŸ"
                                    } catch (Exception tarEx) {
                                        echo "TAR è§£å‹å¤±è´¥ï¼Œå°è¯•æŒ‰ TAR.GZ æ ¼å¼è§£å‹"
                                        untar file: uploadedArchive, compression: 'gzip', quiet: false
                                        echo "âœ… æŒ‰ TAR.GZ æ ¼å¼è§£å‹æˆåŠŸ"
                                    }
                                }
                            }
                        } catch (Exception e) {
                            echo "âŒ Pipeline Utility Steps è§£å‹å¤±è´¥: ${e.getMessage()}"
                            echo "å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•è§£å‹..."
                            
                            // å›é€€åˆ°ä¼ ç»Ÿå‘½ä»¤è¡Œè§£å‹
                            if (uploadedArchive.endsWith('.zip')) {
                                echo "ä½¿ç”¨ Python è§£å‹ ZIP æ–‡ä»¶"
                                sh '''
                                    python3 -c "
import zipfile
import sys
try:
    with zipfile.ZipFile('${uploadedArchive}', 'r') as zip_ref:
        zip_ref.extractall('.')
    print('âœ… Python ZIP è§£å‹æˆåŠŸ')
except Exception as e:
    print(f'âŒ Python ZIP è§£å‹å¤±è´¥: {e}')
    sys.exit(1)
                                    "
                                '''
                            } else if (uploadedArchive.endsWith('.tar.gz') || uploadedArchive.endsWith('.tgz')) {
                                echo "ä½¿ç”¨ tar è§£å‹ TAR.GZ æ–‡ä»¶"
                                sh "tar -xzf '${uploadedArchive}'"
                            } else if (uploadedArchive.endsWith('.tar')) {
                                echo "ä½¿ç”¨ tar è§£å‹ TAR æ–‡ä»¶"
                                sh "tar -xf '${uploadedArchive}'"
                            }
                        }
                        
                        echo "ğŸ“ è§£å‹åå·¥ä½œç©ºé—´å†…å®¹:"
                        sh "ls -la"
                    }
                    
                    // éªŒè¯æ„å»ºç›®å½•å’Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    sh """
                        if [ ! -d "${BUILD_CONTEXT_PATH}" ]; then
                            echo "âŒ é”™è¯¯: æ„å»ºç›®å½• ${BUILD_CONTEXT_PATH} ä¸å­˜åœ¨"
                            echo "ğŸ“ å½“å‰ç›®å½•å†…å®¹:"
                            find . -type d -maxdepth 2
                            exit 1
                        fi
                        
                        if [ ! -f "${DOCKERFILE_PATH}" ]; then
                            echo "âŒ é”™è¯¯: Dockerfile ${DOCKERFILE_PATH} ä¸å­˜åœ¨"
                            echo "ğŸ“ æ„å»ºç›®å½•å†…å®¹:"
                            ls -la ${BUILD_CONTEXT_PATH}/
                            exit 1
                        fi
                        
                        echo "âœ… æ„å»ºæ–‡ä»¶éªŒè¯é€šè¿‡"
                        echo "ğŸ“ æ„å»ºç›®å½•å†…å®¹:"
                        ls -la ${BUILD_CONTEXT_PATH}/
                    """
                }
            }
        }

        stage("æ„å»ºå‡†å¤‡") {
            agent {
                kubernetes {
                    yaml PREP_POD_YAML
                    defaultContainer 'python'
                }
            }
            steps {
                script {
                    echo "ğŸ”§ æ„å»ºå‡†å¤‡é˜¶æ®µ"
                    
                    // å¤„ç†å”¯ä¸€ID - é€šå¸¸ç”±Pythonè„šæœ¬ç”Ÿæˆå¹¶ä¼ é€’
                    def uniqueId = params.BUILD_UNIQUE_ID
                    if (!uniqueId || uniqueId.trim().isEmpty()) {
                        uniqueId = "${new Date().format('yyyyMMddHHmmss')}-${BUILD_NUMBER}-${UUID.randomUUID().toString().substring(0, 8)}"
                        echo "ğŸ“‹ Jenkinsç”Ÿæˆå”¯ä¸€ID: ${uniqueId}"
                    } else {
                        echo "ğŸ“‹ ä½¿ç”¨ä¼ é€’çš„å”¯ä¸€ID: ${uniqueId}"
                    }
                    env.ACTUAL_UNIQUE_ID = uniqueId
                    
                    // å¤„ç†å¹³å°é…ç½®
                    def platformsStr = params.BUILD_PLATFORMS
                    echo "ğŸ” åŸå§‹å¹³å°å‚æ•°: '${platformsStr}'"
                    
                    def platforms = platformsStr.split(',')
                    def platformsInfo = []
                    
                    echo "ğŸ—ï¸  å¤šå¹³å°æ„å»ºé…ç½®:"
                    echo "   é€‰æ‹©çš„å¹³å°: ${platformsStr}"
                    echo "   åˆ†å‰²åå¹³å°æ•°é‡: ${platforms.length}"
                    
                    for (platform in platforms) {
                        def cleanPlatform = platform.trim()
                        platformsInfo.add(cleanPlatform)
                        echo "   - å¹³å°: '${cleanPlatform}'"
                    }
                    
                    env.PLATFORM_LIST = platformsInfo.join(',')
                    env.IS_MULTI_PLATFORM = (platforms.length > 1).toString()
                    
                    echo "ğŸ” ç¯å¢ƒå˜é‡è®¾ç½®:"
                    echo "   PLATFORM_LIST: '${env.PLATFORM_LIST}'"
                    echo "   IS_MULTI_PLATFORM: '${env.IS_MULTI_PLATFORM}'"
                    
                    echo "ğŸ“‹ æ„å»ºé…ç½®ä¿¡æ¯:"
                    echo "   åº”ç”¨åç§°: ${params.APP_NAME}"
                    echo "   åº”ç”¨ç‰ˆæœ¬: ${params.APP_VERSION}" 
                    echo "   æ„å»ºå”¯ä¸€ID: ${uniqueId}"
                    echo "   é•œåƒåç§°: ${IMAGE_NAME}"
                    echo "   é•œåƒæ ‡ç­¾: ${IMAGE_TAG}"
                    echo "   Harbor ä»“åº“: ${HARBOR_REGISTRY}"
                    echo "   é¡¹ç›®: ${HARBOR_PROJECT}"
                    echo "   æ„å»ºå¹³å°: ${env.PLATFORM_LIST}"
                    echo "   å¤šå¹³å°æ„å»º: ${env.IS_MULTI_PLATFORM}"
                    
                    // æ˜¾ç¤ºæ„å»ºä¿¡æ¯
                    sh """
                        echo "=== æ„å»ºä¿¡æ¯ ==="
                        echo "æ„å»ºå·: ${BUILD_NUMBER}"
                        echo "æ„å»ºå”¯ä¸€ID: ${uniqueId}"
                        echo "æ„å»ºæ—¶é—´: \$(date)"
                        echo "æ„å»ºèŠ‚ç‚¹: \$(hostname)"
                        echo "Jenkins URL: ${JENKINS_URL}"
                        echo "åŸå§‹æ–‡ä»¶å: \${BUILD_ARCHIVE_FILENAME:-'æœªè®¾ç½®'}"
                        echo "å®é™…ä½¿ç”¨æ–‡ä»¶: ${env.ACTUAL_ARCHIVE_FILE}"
                        echo "æ„å»ºå¹³å°: ${env.PLATFORM_LIST}"
                        echo "å¤šå¹³å°æ¨¡å¼: ${env.IS_MULTI_PLATFORM}"
                    """

                    echo "ğŸ“¦ Stashing build context for parallel stages..."
                    stash includes: "${params.BUILD_CONTEXT}/**", name: "build-context-${env.ACTUAL_UNIQUE_ID}"
                }
            }
        }

        stage("å¤šå¹³å°é•œåƒæ„å»º") {
            agent {
                kubernetes {
                    yaml PREP_POD_YAML
                    defaultContainer 'python'
                }
            }
            steps {
                script {
                    def platforms = env.PLATFORM_LIST.split(',')
                    echo "ğŸš€ å¼€å§‹æ„å»º ${platforms.length} ä¸ªå¹³å°: ${env.PLATFORM_LIST}"
                }
            }
        }
        
        stage("å¹¶è¡Œæ„å»ºæ‰§è¡Œ") {
            failFast true
            parallel {
                stage('æ„å»º AMD64') {
                    when {
                        expression { 
                            return env.PLATFORM_LIST.contains('linux/amd64')
                        }
                    }
                    agent {
                        kubernetes {
                            yaml KANIKO_POD_YAML
                        }
                    }
                    steps {
                        script {
                            echo "ğŸ–¥ï¸  æ„å»º AMD64 é•œåƒ"
                            echo "ğŸ“¦ Unstashing build context..."
                            unstash name: "build-context-${env.ACTUAL_UNIQUE_ID}"
                            buildPlatformImage('linux/amd64', 'amd64')
                        }
                    }
                    post {
                        failure {
                            echo "âŒ AMD64 å¤±è´¥"
                        }
                    }
                }
                
                stage('æ„å»º ARM64') {
                    when {
                        expression { 
                            return env.PLATFORM_LIST.contains('linux/arm64')
                        }
                    }
                    agent {
                        kubernetes {
                            yaml KANIKO_POD_YAML
                        }
                    }
                    steps {
                        script {
                            echo "ğŸ’ª æ„å»º ARM64 é•œåƒ"
                            echo "ğŸ“¦ Unstashing build context..."
                            unstash name: "build-context-${env.ACTUAL_UNIQUE_ID}"
                            buildPlatformImage('linux/arm64', 'arm64')
                        }
                    }
                    post {
                        failure {
                            echo "âŒ ARM64 å¤±è´¥"
                        }
                    }
                }
            }
        }

        stage("æ„å»ºç»“æœæ±‡æ€»") {
            agent {
                kubernetes {
                    yaml PREP_POD_YAML
                    defaultContainer 'python'
                }
            }
            steps {
                script {
                    def platforms = env.PLATFORM_LIST.split(',')
                    def builtPlatforms = []
                    
                    for (platform in platforms) {
                        def cleanPlatform = platform.trim()
                        if (cleanPlatform == 'linux/amd64' || cleanPlatform == 'linux/arm64') {
                            builtPlatforms.add(cleanPlatform)
                        }
                    }
                    
                    echo "ğŸ“Š æ„å»ºå®Œæˆ: ${params.APP_NAME}:${IMAGE_TAG} (${builtPlatforms.size()}å¹³å°)"
                    echo ""
                    echo "ğŸ¯ æ„å»ºçš„é•œåƒ:"
                    
                    for (platform in builtPlatforms) {
                        def platformArch = platform.replace('linux/', '')
                        echo "   ${IMAGE_NAME}:${IMAGE_TAG}-${platformArch}"
                        echo "   ${IMAGE_NAME}:latest-${platformArch}"
                    }
                    
                    echo ""
                    echo "ğŸŒ Harbor: ${HARBOR_REGISTRY}/harbor/projects/${HARBOR_PROJECT}/repositories/${params.APP_NAME}"
                }
            }
        }
    }

    post {
        always {
            agent {
                kubernetes {
                    yaml PREP_POD_YAML
                    defaultContainer 'python'
                }
            }
            script {
                echo "ğŸ§¹ æ„å»ºå®Œæˆ - ç¼–å·: ${BUILD_NUMBER}"
            }
        }
        success {
            agent {
                kubernetes {
                    yaml PREP_POD_YAML
                    defaultContainer 'python'
                }
            }
            script {
                def platforms = env.PLATFORM_LIST?.split(',') ?: []
                def builtPlatforms = []
                
                for (platform in platforms) {
                    def cleanPlatform = platform.trim()
                    if (cleanPlatform == 'linux/amd64' || cleanPlatform == 'linux/arm64') {
                        builtPlatforms.add(cleanPlatform.replace('linux/', ''))
                    }
                }
                
                echo "ğŸ‰ æ„å»ºæˆåŠŸ - ${params.APP_NAME}:${IMAGE_TAG}"
                echo "âœ… å¹³å°: ${builtPlatforms.join(', ')}"
            }
        }
        failure {
            agent {
                kubernetes {
                    yaml PREP_POD_YAML
                    defaultContainer 'python'
                }
            }
            script {
                echo "âŒ æ„å»ºå¤±è´¥ - ${params.APP_NAME}:${IMAGE_TAG}"
            }
        }
    }
}

// ç”Ÿæˆé•œåƒæ ‡ç­¾çš„å‡½æ•°
def generateImageTag() {
    def strategy = params.IMAGE_TAG_STRATEGY ?: 'version-build'
    
    switch(strategy) {
        case 'version-build':
            return "${params.APP_VERSION}"
        case 'timestamp':
            return "${params.APP_VERSION}-${new Date().format('yyyyMMdd-HHmmss')}"
        case 'latest':
            return 'latest'
        default:
            return "${params.APP_VERSION}"
    }
}

// è§£æå¹³å°åˆ—è¡¨çš„å‡½æ•°
def parsePlatforms(platformsStr) {
    return platformsStr.split(',').collect { it.trim() }.join(',')
}

// æ„å»ºæŒ‡å®šå¹³å°é•œåƒçš„å‡½æ•°
def buildPlatformImage(String platform, String platformArch) {
    container(name: 'kaniko', shell: '/busybox/sh') {
        sh """#!/busybox/sh
            # éªŒè¯æ–‡ä»¶
            if [ ! -f "${DOCKERFILE_PATH}" ]; then
                echo "âŒ Dockerfile ä¸å­˜åœ¨: ${DOCKERFILE_PATH}"
                exit 1
            fi
            
            # æ‰§è¡Œæ„å»º
            /kaniko/executor \\
                --dockerfile=${DOCKERFILE_PATH} \\
                --context=${BUILD_CONTEXT_PATH} \\
                --destination=${IMAGE_NAME}:${IMAGE_TAG}-${platformArch} \\
                --destination=${IMAGE_NAME}:latest-${platformArch} \\
                --custom-platform=${platform} \\
                --build-arg=TARGETARCH=${platformArch} \\
                --build-arg=BUILDPLATFORM=${platform} \\
                --cache=true \\
                --cache-ttl=24h \\
                --cleanup
        """
    }
} 